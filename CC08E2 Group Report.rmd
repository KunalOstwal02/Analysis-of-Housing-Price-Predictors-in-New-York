---
title: "CC08E2: Group Project"
author: "Kunal Ostwal - 500668171"
date: "2022-10-05"
output: ioslides_presentation
---
## Abstract: 
> A one paragraph summary of what you set out to learn, and what you ended up finding. It should summarise the entire report.
    

## Introduction: 
A discussion of what questions you are trying to answer.
    
## Data set: 
> Describe details about how the data set was collected (if known) and the variables in the data set.


    
## Analysis:
Describe how you used multiple regression to analyse the data set. Specifically, you should discuss how you carried out the steps in analysis discussed in class, i.e., exploration of data to find an initial reasonable model (variable selection), checking the model and any changes to the model based on your checking of the model (e.g. transformations).

### Simple regression

### Complex regression

## Assumtpions

## Results: 
We set out working on this group project with the goal of finding the factors which have the strongest relationship with Price.

## Age vs Price
The first relationship we tested was between Age and Price. The plot showed us that the relationship between Age and Price was inversely related.
```{r, out.width="45%", fig.align='center', message=FALSE, echo=FALSE}
houses %>% ggplot() + 
  aes(y = Price, x = Age) + 
  geom_point(alpha = 0.25) + 
  geom_smooth(method = lm) + 
  labs(x = "Age") + 
  scale_y_continuous(labels = comma)
```

## Price vs Bedrooms
In addition to testing the relationship between Age and Price, we also tested the relationship between Price and Bedrooms and  Price and Heat Type. The plot for Price and Bathroom showed us that the price is not directly proportional to the number of bedrooms in the house. If a house has more number of bedrooms, It has not mean that it will be more expensive than a house with lesser number of bedrooms.
```{r, out.width="45%", fig.align='center', message=FALSE, echo=FALSE}
houses %>% ggplot() + 
  aes(x = Price, y = Bedrooms, group = Bedrooms) + 
  geom_boxplot(alpha = 0.5) + 
  scale_y_continuous(breaks = 1:8)
```

## Price vs Heat Type
We observe here that houses with Hot Air have higher chances of being expensive when compared to houses with Electric Heat or Hot Water or None.
```{r, out.width="45%", fig.align='center', message=FALSE, echo=FALSE}
houses %>% ggplot() + 
  aes(y = Price, x = Heat.Type, color = Heat.Type) + 
  geom_boxplot(alpha = 0.5) 
```

## Correlation Matrix
We used a correlation matrix to check which factor has the highest correlation relationship with Price. The correlation matrix heatmap showed that the Price and Living Area factor pair had the highest correlation relationship.
```{r}
# select numeric or integer type factors
temp = select(houses, - which(sapply(houses, class) == "factor"))
cor_mat = cor(temp)

melted_cor_mat = cor_mat %>%
  data.frame() %>% 
  rownames_to_column(var = "var1") %>% 
  gather(key = "var2", value = "cor", -var1)

# correlation matrix heatmap
melted_cor_mat %>% ggplot() + 
  aes(x=var1, y=var2, fill=cor) + 
  geom_tile() + theme_minimal(base_size = 15) +
  scale_fill_gradient2(
    low = "red", high = "darkgreen", mid = "white", 
    midpoint = 0, limit = c(-1,1)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# interactive plot using 'qtlcharts'
iplotCorr(temp)
```
## Forward Model and Backward Model
Both Forward and Backward Model deliver the same results.
```{r}
lm = lm(Price ~ Living.Area, data = houses)
M0 = lm(Price ~ 1, data = houses)
M1 = lm(Price ~ ., data = houses)
M0 = lm(Price ~ 1, data = houses)  # Null model
Mf = lm(Price ~ . - Test, data = houses)  # Full model
step_back = step(Mf, direction = "backward", trace = FALSE)
step_forward = step(M0, scope = list(lower = M0, upper = Mf), direction = "forward", trace = FALSE)
sjPlot::tab_model(step_forward, step_back, show.ci = FALSE, show.aic = TRUE,
 dv.labels = c("Forward model", "Backward model"))
```
    
## Discussion and conclusion: 
Describe any limitations of your analysis and how they might be overcome in future research and provide brief conclusions about the results of your study.



## Exploratory Data Analysis

**Dataset:** House Prices of New York  
**Variable of Interest:** Age

```{r, message=FALSE, echo=FALSE}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(psych)
library(scales)
library(qtlcharts)
```

```{r, message=FALSE, echo=FALSE}
#houses <- read.table(file = ".\\resources\\housing-prices-ge19.txt", sep = "\t", header = TRUE)
houses <- read.table(file = "./resources/housing-prices-ge19.txt", sep = "\t", header = TRUE)

```

```{r, echo=FALSE, message=FALSE}
houses <- houses %>% 
  mutate(
    Waterfront = factor(Waterfront),
    New.Construct = factor(New.Construct),
    Central.Air = factor(Central.Air),
    Fuel.Type = factor(Fuel.Type),
    Heat.Type = factor(Heat.Type),
    Sewer.Type = factor(Sewer.Type),
    Test = factor(Test)
  )

```
```{r}
str(houses)
```

```{r, warning=FALSE}
describe(houses[, c("Price" ,"Lot.Size", "Age", "Land.Value", "Living.Area", "Pct.College", "Bedrooms", "Fireplaces", "Bathrooms", "Rooms")], fast=TRUE)
```
### Age vs Price
```{r, out.width="45%", fig.align='center', message=FALSE, echo=FALSE}
houses %>% ggplot() + 
  aes(y = Price, x = Age) + 
  geom_point(alpha = 0.25) + 
  geom_smooth(method = lm) + 
  labs(x = "Age") + 
  scale_y_continuous(labels = comma)
```
Although at the risk of extrapolation, one can infer that age and price are inversely related.  

### Age vs Bedrooms

```{r, out.width="45%", fig.align='center', message=FALSE, echo=FALSE}
houses %>% ggplot() + 
  aes(x = Age, y = Bedrooms, group = Bedrooms) + 
  geom_boxplot(alpha = 0.5) + 
  scale_y_continuous(breaks = 1:8)
```

We observe that the houses with 5+ bedrooms are comparatively older that <5 bedrooms houses. For less than 5 bedroom houses, the trend is opposite. Four bedroom houses have been built more recently than 1 bedroom houses.  

### Age vs Heat Type
```{r, out.width="45%", fig.align='center', message=FALSE, echo=FALSE}
houses %>% ggplot() + 
  aes(y = Age, x = Heat.Type, color = Heat.Type) + 
  geom_boxplot(alpha = 0.5) 
```
We observe here that houses with no heating system are older than ones that have a heating system.  

```{r}
houses[,-which(sapply(df, class) == "factor")]

houses_cor_mat = houses[,-which(sapply(df, class) == "factor")] %>%
  data.frame() %>% 
  rownames_to_column(var = "var1") %>% 
  gather(key = "var2", value = "cor", -var1)

```

## Analyzing the factors that determine the price of the house

We can see in the correlation matrix that the `Price`, `Living.Area` factor pair has the highest correlation relationship. 
```{r}
# select numeric or integer type factors
temp = select(houses, - which(sapply(houses, class) == "factor"))
cor_mat = cor(temp)

melted_cor_mat = cor_mat %>%
  data.frame() %>% 
  rownames_to_column(var = "var1") %>% 
  gather(key = "var2", value = "cor", -var1)

# correlation matrix heatmap
melted_cor_mat %>% ggplot() + 
  aes(x=var1, y=var2, fill=cor) + 
  geom_tile() + theme_minimal(base_size = 15) +
  scale_fill_gradient2(
    low = "red", high = "darkgreen", mid = "white", 
    midpoint = 0, limit = c(-1,1)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# interactive plot using 'qtlcharts'
iplotCorr(temp)
```

```{r}
lm = lm(Price ~ Living.Area, data = houses)

#plot(Price ~ Living.Area, data = housing)
#abline(lm, lwd = 3, col = "red")

houses %>% ggplot() + 
  aes(y = Price, x = Living.Area) + 
  geom_point(alpha = 0.25) + 
  geom_smooth(method = "lm") + 
  labs(x = "Age") + 
  scale_y_continuous(labels = comma)
```
```{r}
summary(lm)
```

```{r}
M0 = lm(Price ~ 1, data = houses)

M1 = lm(Price ~ ., data = houses)

```         

```{r}
round(summary(M1)$coef,3)
```
```{r}
res = bind_rows(broom::glance(M1),
                broom::glance(M0))

res$model = c("All", "Null")
res %>% pivot_longer(
  cols = -model,
  names_to = "metric",
  values_to = "value"
) %>% pivot_wider(names_from = "model") %>% 
  gt::gt() %>%
  gt::fmt_number(columns = 2:3,
                 decimals = 2) %>% 
  gt::fmt_missing()
  
  
```


### Forward and Backward Model

```{r}
M0 = lm(Price ~ 1, data = houses)  # Null model
Mf = lm(Price ~ . - Test, data = houses)  # Full model
```

```{r}
step_back = step(Mf, direction = "backward", trace = FALSE)

summary(step_back)

step_forward = step(M0, scope = list(lower = M0, upper = Mf), direction = "forward", trace = FALSE)

summary(step_forward)
```


## Comparison of backward and forward model

```{r}
sjPlot::tab_model(step_forward, step_back, show.ci = FALSE, show.aic = TRUE,
  dv.labels = c("Forward model", "Backward model"))
```

## Assumptions
```{r}
M1 = step_forward
```


1.  Linearity: The residuals plotted appear symmetrically distributed above and below zero with some outliers above zero, therefore the data is assumed to be linear.

```{r}
# Checking assumtpions - Linearity and Homoskedacity


plot(lm$residuals)	
abline(h=0, lwd = 3, col = "red")
plot(M1$residuals)
abline(h=0, lwd = 3, col = "red")

```
2.  Independence: We take it for granted that the data has been independently collected.

3.  Homoskedacity: In both models, it appears the variance is constant in the QQ plot for each error term and therefore the homoskedacity assumption is satisfied.

4.  Normality: The majority of points lie close to the diagonal line in both QQ plots, however, there are many outliers in the upper tail so the normality assumption is moderately well satisfied. Furthermore, we have a large sample size, and so can use the central limit theorem to justify approximately valid inferences under a normality assumption.

```{r}
# Checking assumptions - Normality

lm.res = lm$residuals
M1.res = M1$residuals

ggplot(data.frame(lm.res)) +
  aes(sample = lm.res) + 
  geom_qq_line() + 
  geom_qq(size=1)

ggplot(data.frame(M1.res)) +
  aes(sample = M1.res) + 
  geom_qq_line() + 
  geom_qq(size=1)
```


## Performance Analysis

Here we compare the performance of the multi-variate regression model to that of the simple linear regression model.

### In-sample Performance

Simple Model Performance: `r summary(lm)$r.squared`
Multivariate Model Performance: `r summary(step_forward)$r.squared`

### Out of Sample Performance
```{r}
set.seed(2)
n = nrow(houses)
```
```{r}
n_train = floor(0.8*n)
n_test = n - n_train
grp_labs = rep(c("Train", "Test"), times = c(n_train, n_test))
houses$grp = sample(grp_labs)
train_dat = houses %>% filter(grp == "Train")

lm_simple_train = lm(Price ~ Living.Area, data = train_dat)
lm_full_train = lm(formula = Price ~ Lot.Size + Waterfront + Age + 
    Land.Value + New.Construct + Central.Air + Heat.Type + Living.Area + 
    Bedrooms + Bathrooms + Rooms, data = train_dat)

test_dat = houses %>% filter(grp == "Test")
simple_pred = predict(lm_simple_train, newdata = test_dat)
full_pred = predict(lm_full_train, newdata = test_dat)

```

We compare the mean absolute error of the two models.  
MAE(Simple Model) = `r mean(abs(test_dat$Price - simple_pred))`  
MAE(Full Model) = `r mean(abs(test_dat$Price - full_pred))`

## 10-fold Cross Validation

```{r}
set.seed(2)
nrow(houses)
```

```{r}
houses$grp = NULL
fold_id = c(rep(1:17, each = 102))
houses$fold_id = sample(fold_id, replace = FALSE)
head(houses)
```



```{r}
k = 10
simple_mse = full_mse = vector(mode = "numeric", length = k)
simple_mae = full_mae = vector(mode = "numeric", length = k)

for (i in 1:k) {
  test_set = houses[fold_id == i,]
  training_set = houses[fold_id != i,]
  simple_lm = lm(Price ~ Living.Area, data = training_set)
  simple_pred = predict(simple_lm, test_set)
  simple_mse[i] = mean((test_set$Price - simple_pred) ^ 2)
  simple_mae[i] = mean(abs(test_set$Price - simple_pred))
  full_lm = lm(formula = Price ~ Lot.Size + Waterfront + Age + 
    Land.Value + New.Construct + Central.Air + Heat.Type + Living.Area + 
    Bedrooms + Bathrooms + Rooms, data = training_set)
  full_pred = predict(full_lm, test_set)
  full_mse[i] = mean((test_set$Price - full_pred)^2)
  full_mae[i] = mean(abs(test_set$Price - full_pred))
}
```



```{r}
cv_res = tibble(simple_mse, full_mse, simple_mae, full_mae)
cv_res
```

```{r}
c(sqrt(mean(simple_mse)),
  sqrt(mean(full_mse))) %>% round(2)

c(mean(simple_mae),
  mean(full_mae)) %>% round(2)
```

```{r}
cv_res %>% gather(key = "metric", value = "error") %>% 
  separate(col = metric, into = c("model","metric")) %>% 
  ggplot(aes(x = model, y = error)) + facet_wrap(~metric, scales = "free_y") + 
  geom_boxplot() 
```


```{r}
library(caret)
cv_full = train(
  Price ~ Lot.Size + Waterfront + Age + 
    Land.Value + New.Construct + Central.Air + Heat.Type + Living.Area + 
    Bedrooms + Bathrooms + Rooms, houses,
  method = "lm",
  trControl = trainControl(
    method = "cv", number = 10,
    verboseIter = FALSE
  )
)
cv_full

```

```{r}
cv_simple = train(
  Price ~ Living.Area, 
  houses,
  method = "lm",
  trControl = trainControl(
    method = "cv", number = 10,
    verboseIter = FALSE
  )
)
cv_simple
```













